{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ijGzTHJJUCPY",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Copyright 2024 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEqbX8OhE8y9"
      },
      "source": [
        "# Intro to Google Cloud - Langchain\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2Faamonten%2Fgdg-langchain01%2Fmain%2F1-%20Intro%20-%20Langchain.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\"><br> Run in Colab Enterprise\n",
        "    </a>\n",
        "  </td>    \n",
        "</table>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lU7fYNoHW4BP"
      },
      "source": [
        "| | |\n",
        "|-|-|\n",
        "|Author(s) | [Eric Dong](https://github.com/gericdong) |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CkHPv2myT2cx"
      },
      "source": [
        "## Overview\n",
        "\n",
        "This notebook demonstrates how to send chat prompts to the Gemini 1.0 Pro model (`gemini-1.0-pro`) by using the Vertex AI SDK for Python and LangChain. Gemini 1.0 Pro supports prompts with text-only input, including natural language tasks, multi-turn text and code chat, and code generation. It can output text and code.\n",
        "\n",
        "Learn more about [Sending chat prompt requests (Gemini)](https://cloud.google.com/vertex-ai/docs/generative-ai/multimodal/send-chat-prompts-gemini)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DrkcqHrrwMAo"
      },
      "source": [
        "### Objectives\n",
        "\n",
        "In this tutorial, you learn how to send chat prompts to the Gemini 1.0 Pro model (`gemini-1.0-pro`) using the Vertex AI SDK for Python and LangChain.\n",
        "\n",
        "You will complete the following tasks:\n",
        "\n",
        "- Sending chat prompts using Vertex AI SDK for Python\n",
        "- Sending chat prompts using LangChain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9nEPojogw-g"
      },
      "source": [
        "### Costs\n",
        "This tutorial uses billable components of Google Cloud:\n",
        "\n",
        "- Vertex AI\n",
        "\n",
        "Learn about [Vertex AI pricing](https://cloud.google.com/vertex-ai/pricing) and use the [Pricing Calculator](https://cloud.google.com/products/calculator/) to generate a cost estimate based on your projected usage."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r11Gu7qNgx1p"
      },
      "source": [
        "## Getting Started"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "No17Cw5hgx12"
      },
      "source": [
        "### Install libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tFy3H3aPgx12",
        "tags": []
      },
      "outputs": [],
      "source": [
        "! pip3 install --upgrade --quiet google-cloud-aiplatform \\\n",
        "                                 langchain-google-vertexai \\\n",
        "                                 langchain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7UyNVSiyQ96"
      },
      "source": [
        "### Restart current runtime\n",
        "\n",
        "To use the newly installed packages in this Jupyter runtime, you must restart the runtime. You can do this by running the cell below, which restarts the current kernel.\n",
        "\n",
        "The restart might take a minute or longer. After its restarted, continue to the next step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YmY9HVVGSBW5",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import IPython\n",
        "\n",
        "app = IPython.Application.instance()\n",
        "app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXQZrM5hQeKb"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "<b>⚠️ Wait for the kernel to finish restarting before you continue. ⚠️</b>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmWOrTJ3gx13"
      },
      "source": [
        "### Authenticate your notebook environment (Colab only)\n",
        "\n",
        "If you are running this notebook on Google Colab, run the cell below to authenticate your environment.\n",
        "\n",
        "This step is not required if you are using [Vertex AI Workbench](https://cloud.google.com/vertex-ai-workbench)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "executionInfo": {
          "elapsed": 1,
          "status": "ok",
          "timestamp": 1709890060371,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -60
        },
        "id": "NyKGtVQjgx13",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "# Additional authentication is required for Google Colab\n",
        "if \"google.colab\" in sys.modules:\n",
        "    # Authenticate user to Google Cloud\n",
        "    from google.colab import auth\n",
        "\n",
        "    auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DF4l8DTdWgPY"
      },
      "source": [
        "### Define Google Cloud project information and initialize Vertex AI\n",
        "\n",
        "Initialize the Vertex AI SDK for Python for your project:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "executionInfo": {
          "elapsed": 51066,
          "status": "ok",
          "timestamp": 1709890141962,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -60
        },
        "id": "Nqwi-5ufWp_B",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Define project information\n",
        "PROJECT_ID = \"gdg-langchain24cph-4180\"  # @param {type:\"string\"}\n",
        "LOCATION = \"us-central1\"  # @param {type:\"string\"}\n",
        "\n",
        "# Initialize Vertex AI\n",
        "import vertexai\n",
        "\n",
        "vertexai.init(project=PROJECT_ID, location=LOCATION)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXHfaVS66_01"
      },
      "source": [
        "### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "executionInfo": {
          "elapsed": 6446,
          "status": "ok",
          "timestamp": 1709890169265,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -60
        },
        "id": "lslYAvw37JGQ",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from IPython.display import Markdown\n",
        "from langchain.chains import ConversationChain\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.prompts import (\n",
        "    ChatPromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        "    MessagesPlaceholder,\n",
        "    SystemMessagePromptTemplate,\n",
        ")\n",
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "from langchain_google_vertexai import ChatVertexAI, HarmBlockThreshold, HarmCategory\n",
        "from vertexai.generative_models import Content, GenerativeModel, Part"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4437b7608c8e"
      },
      "source": [
        "## Sending chat prompts using Vertex AI SDK for Python\n",
        "\n",
        "### Load the Gemini 1.0 Pro model\n",
        "\n",
        "Gemini 1.0 Pro supports text and code generation from a text prompt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "executionInfo": {
          "elapsed": 1118,
          "status": "ok",
          "timestamp": 1709890411276,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -60
        },
        "id": "2998506fe6d1",
        "tags": []
      },
      "outputs": [],
      "source": [
        "model = GenerativeModel(\"gemini-1.0-pro\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wl2AZceWjXoy"
      },
      "source": [
        "### Start a chat session\n",
        "\n",
        "You start a stateful chat session and then send chat prompts with configuration parameters including generation configurations and safety settings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 4734,
          "status": "ok",
          "timestamp": 1709890584414,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -60
        },
        "id": "_vLprtHAjNOO",
        "outputId": "1f1a998a-e27f-4a73-98dc-62914143f8c2",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mars has **two** moons: Phobos and Deimos.\n",
            "\n",
            "**Fun Facts about Phobos:**\n",
            "\n",
            "* Phobos is the larger of the two moons, with a diameter of about 22.5 kilometers (14 miles).\n",
            "* It orbits Mars three times a day, making it the fastest-orbiting moon in the solar system.\n",
            "* Phobos is covered in craters and has a very irregular shape, resembling a potato.\n",
            "* Scientists believe that Phobos may be a captured asteroid that was once independent of Mars.\n",
            "\n",
            "**Fun Facts about Deimos:**\n",
            "\n",
            "* Deimos is the smaller of the two moons, with a diameter of only about 12.6 kilometers (7.8 miles).\n",
            "* It orbits Mars once every 30 hours.\n",
            "* Deimos is also covered in craters but has a more rounded shape than Phobos.\n",
            "* Unlike Phobos, Deimos is thought to have formed from the same material that formed Mars.\n"
          ]
        }
      ],
      "source": [
        "chat = model.start_chat()\n",
        "\n",
        "response = chat.send_message(\n",
        "    \"\"\"You are an astronomer, knowledgeable about the solar system.\n",
        "How many moons does Mars have? Tell me some fun facts about them.\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e45ReUIxvTxX"
      },
      "source": [
        "You can use `Markdown` to display the generated text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "executionInfo": {
          "elapsed": 5,
          "status": "ok",
          "timestamp": 1709890589571,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -60
        },
        "id": "8QU6brtOuyAx",
        "outputId": "e284c458-1a5d-464b-c05b-16f3ee223f02",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "Mars has **two** moons: Phobos and Deimos.\n",
              "\n",
              "**Fun Facts about Phobos:**\n",
              "\n",
              "* Phobos is the larger of the two moons, with a diameter of about 22.5 kilometers (14 miles).\n",
              "* It orbits Mars three times a day, making it the fastest-orbiting moon in the solar system.\n",
              "* Phobos is covered in craters and has a very irregular shape, resembling a potato.\n",
              "* Scientists believe that Phobos may be a captured asteroid that was once independent of Mars.\n",
              "\n",
              "**Fun Facts about Deimos:**\n",
              "\n",
              "* Deimos is the smaller of the two moons, with a diameter of only about 12.6 kilometers (7.8 miles).\n",
              "* It orbits Mars once every 30 hours.\n",
              "* Deimos is also covered in craters but has a more rounded shape than Phobos.\n",
              "* Unlike Phobos, Deimos is thought to have formed from the same material that formed Mars."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Markdown(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2axT2nKuVzP"
      },
      "source": [
        "You can check out the metadata of the response including the `safety_ratings` and `usage_metadata`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 1610,
          "status": "ok",
          "timestamp": 1709890595784,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -60
        },
        "id": "ih0v9B1vspiF",
        "outputId": "2ae49436-cad8-4dc5-ee03-301869069f03",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "candidates {\n",
            "  content {\n",
            "    role: \"model\"\n",
            "    parts {\n",
            "      text: \"Mars has **two** moons: Phobos and Deimos.\\n\\n**Fun Facts about Phobos:**\\n\\n* Phobos is the larger of the two moons, with a diameter of about 22.5 kilometers (14 miles).\\n* It orbits Mars three times a day, making it the fastest-orbiting moon in the solar system.\\n* Phobos is covered in craters and has a very irregular shape, resembling a potato.\\n* Scientists believe that Phobos may be a captured asteroid that was once independent of Mars.\\n\\n**Fun Facts about Deimos:**\\n\\n* Deimos is the smaller of the two moons, with a diameter of only about 12.6 kilometers (7.8 miles).\\n* It orbits Mars once every 30 hours.\\n* Deimos is also covered in craters but has a more rounded shape than Phobos.\\n* Unlike Phobos, Deimos is thought to have formed from the same material that formed Mars.\"\n",
            "    }\n",
            "  }\n",
            "  finish_reason: STOP\n",
            "  safety_ratings {\n",
            "    category: HARM_CATEGORY_HATE_SPEECH\n",
            "    probability: NEGLIGIBLE\n",
            "  }\n",
            "  safety_ratings {\n",
            "    category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
            "    probability: NEGLIGIBLE\n",
            "  }\n",
            "  safety_ratings {\n",
            "    category: HARM_CATEGORY_HARASSMENT\n",
            "    probability: NEGLIGIBLE\n",
            "  }\n",
            "  safety_ratings {\n",
            "    category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
            "    probability: NEGLIGIBLE\n",
            "  }\n",
            "}\n",
            "usage_metadata {\n",
            "  prompt_token_count: 28\n",
            "  candidates_token_count: 200\n",
            "  total_token_count: 228\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZuHvZevgwdj5"
      },
      "source": [
        "You can retrieve the history of the chat session."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 1459,
          "status": "ok",
          "timestamp": 1709890601724,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -60
        },
        "id": "FYuqKyyktFq7",
        "outputId": "e55d981d-bf01-466a-afac-504ace28c9bd",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[role: \"user\"\n",
            "parts {\n",
            "  text: \"You are an astronomer, knowledgeable about the solar system.\\nHow many moons does Mars have? Tell me some fun facts about them.\\n\"\n",
            "}\n",
            ", role: \"model\"\n",
            "parts {\n",
            "  text: \"Mars has **two** moons: Phobos and Deimos.\\n\\n**Fun Facts about Phobos:**\\n\\n* Phobos is the larger of the two moons, with a diameter of about 22.5 kilometers (14 miles).\\n* It orbits Mars three times a day, making it the fastest-orbiting moon in the solar system.\\n* Phobos is covered in craters and has a very irregular shape, resembling a potato.\\n* Scientists believe that Phobos may be a captured asteroid that was once independent of Mars.\\n\\n**Fun Facts about Deimos:**\\n\\n* Deimos is the smaller of the two moons, with a diameter of only about 12.6 kilometers (7.8 miles).\\n* It orbits Mars once every 30 hours.\\n* Deimos is also covered in craters but has a more rounded shape than Phobos.\\n* Unlike Phobos, Deimos is thought to have formed from the same material that formed Mars.\"\n",
            "}\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "print(chat.history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kiS2CywXxU2y"
      },
      "source": [
        "### Code chat\n",
        "\n",
        "Gemini 1.0 Pro also supports code generation from a text prompt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 2602,
          "status": "ok",
          "timestamp": 1709890610751,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -60
        },
        "id": "1lWiPGQ-cDqC",
        "outputId": "b389b795-722c-486c-b7f2-e7bc4ff1dd4e",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "```python\n",
            "def is_leap_year(year):\n",
            "  \"\"\"\n",
            "  Checks if a year is a leap year.\n",
            "\n",
            "  Args:\n",
            "    year: The year to check.\n",
            "\n",
            "  Returns:\n",
            "    True if the year is a leap year, False otherwise.\n",
            "  \"\"\"\n",
            "\n",
            "  if year % 4 != 0:\n",
            "    return False\n",
            "\n",
            "  if year % 100 == 0 and year % 400 != 0:\n",
            "    return False\n",
            "\n",
            "  return True\n",
            "```\n"
          ]
        }
      ],
      "source": [
        "code_chat = model.start_chat()\n",
        "\n",
        "response = code_chat.send_message(\n",
        "    \"Write a function that checks if a year is a leap year\"\n",
        ")\n",
        "\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kI781aqpy-lH"
      },
      "source": [
        "You can generate unit tests to test the function in this multi-turn chat."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 1434,
          "status": "ok",
          "timestamp": 1709890618373,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -60
        },
        "id": "TGHToON4xyOV",
        "outputId": "85d5b6d2-a63c-466c-912e-857ea01aadc7",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "```python\n",
            "import unittest\n",
            "\n",
            "class TestIsLeapYear(unittest.TestCase):\n",
            "\n",
            "  def test_is_leap_year(self):\n",
            "    self.assertTrue(is_leap_year(2000))\n",
            "    self.assertTrue(is_leap_year(2004))\n",
            "    self.assertTrue(is_leap_year(2008))\n",
            "    self.assertTrue(is_leap_year(2012))\n",
            "    self.assertTrue(is_leap_year(2016))\n",
            "    self.assertTrue(is_leap_year(2020))\n",
            "\n",
            "  def test_is_not_leap_year(self):\n",
            "    self.assertFalse(is_leap_year(1900))\n",
            "    self.assertFalse(is_leap_year(1904))\n",
            "    self.assertFalse(is_leap_year(1908))\n",
            "    self.assertFalse(is_leap_year(1912))\n",
            "    self.assertFalse(is_leap_year(1916))\n",
            "    self.assertFalse(is_leap_year(1920))\n",
            "\n",
            "if __name__ == '__main__':\n",
            "  unittest.main()\n",
            "```\n"
          ]
        }
      ],
      "source": [
        "response = code_chat.send_message(\"Write a unit test of the generated function\")\n",
        "\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jeZNScL7Ci2A"
      },
      "source": [
        "### Add chat history\n",
        "\n",
        "You can add chat history to a chat by adding messages from role `user` and `model` alternately. System messages can be set in the first part for the first message."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 93
        },
        "executionInfo": {
          "elapsed": 1071,
          "status": "ok",
          "timestamp": 1709890692130,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -60
        },
        "id": "JzqUThJv77G9",
        "outputId": "8870e170-593c-4286-f163-2158693a6130",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "Yes\n",
              "\n",
              "Which book series are my favorite movies based on?\n",
              "\n",
              "The Lord of the Rings and The Hobbit"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chat2 = model.start_chat(\n",
        "    history=[\n",
        "        Content(\n",
        "            role=\"user\",\n",
        "            parts=[\n",
        "                Part.from_text(\n",
        "                    \"\"\"\n",
        "    My name is Ned. You are my personal assistant. My favorite movies are Lord of the Rings and Hobbit.\n",
        "    Who do you work for?\n",
        "    \"\"\"\n",
        "                )\n",
        "            ],\n",
        "        ),\n",
        "        Content(role=\"model\", parts=[Part.from_text(\"I work for Ned.\")]),\n",
        "        Content(role=\"user\", parts=[Part.from_text(\"What do I like?\")]),\n",
        "        Content(role=\"model\", parts=[Part.from_text(\"Ned likes watching movies.\")]),\n",
        "    ]\n",
        ")\n",
        "\n",
        "response = chat2.send_message(\"Are my favorite movies based on a book series?\")\n",
        "Markdown(response.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "executionInfo": {
          "elapsed": 1060,
          "status": "ok",
          "timestamp": 1709890707479,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -60
        },
        "id": "G64BrDoxC-K3",
        "outputId": "18747784-d5b6-4b46-dc22-fd019a11abe4",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "1954 and 1937"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response = chat2.send_message(\"When were these books published?\")\n",
        "Markdown(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFlnwb0u54iN"
      },
      "source": [
        "## Sending chat prompts using LangChain\n",
        "\n",
        "The Vertex AI Gemini API is integrated with the LangChain Python SDK, making it convenient to build applications on top of Gemini models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ga2YnFYPXZgh"
      },
      "source": [
        "### Start a chat session\n",
        "\n",
        "You can start a chat by sending chat prompts to the Gemini 1.0 Pro model directly. Gemini 1.0 Pro doesn’t support `SystemMessage` at the moment, but `SystemMessage` can be added to the first human message by setting the `convert_system_message_to_human` to `True`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 2,
          "status": "ok",
          "timestamp": 1709890714022,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -60
        },
        "id": "s41n0UEwGVZV",
        "outputId": "62ae4cf7-9236-4d5f-bdf3-518d9577ba39",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "J'adore la programmation.\n"
          ]
        }
      ],
      "source": [
        "system_message = \"You are a helpful assistant who translates English to French.\"\n",
        "human_message = \"Translate this sentence from English to French. I love programming.\"\n",
        "\n",
        "messages = [SystemMessage(content=system_message), HumanMessage(content=human_message)]\n",
        "\n",
        "chat = ChatVertexAI(\n",
        "    model_name=\"gemini-1.0-pro\",\n",
        "    convert_system_message_to_human=True,\n",
        "    safety_settings={\n",
        "        HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_LOW_AND_ABOVE\n",
        "    },\n",
        ")\n",
        "\n",
        "result = chat.generate([messages])\n",
        "print(result.generations[0][0].text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4VprmGzu4FPO"
      },
      "source": [
        "You can check out the metadata of the generated content."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 4,
          "status": "ok",
          "timestamp": 1709890721325,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -60
        },
        "id": "hBLFXgzsIJhw",
        "outputId": "e38e6059-c73e-44c2-b05f-d10d59f54fe4",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'is_blocked': False, 'safety_ratings': [{'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability_label': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability_label': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability_label': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability_label': 'NEGLIGIBLE', 'blocked': False}], 'citation_metadata': None, 'usage_metadata': {'prompt_token_count': 23, 'candidates_token_count': 6, 'total_token_count': 29}}\n"
          ]
        }
      ],
      "source": [
        "print(result.generations[0][0].generation_info)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RgYHzIUP4PMo"
      },
      "source": [
        "### Use a chat chain with chat prompt template"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 954,
          "status": "ok",
          "timestamp": 1709890727778,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -60
        },
        "id": "9vZr5vyrV-eI",
        "outputId": "e5efd4c9-eb90-41af-a2b7-183369f7ed8f",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content=\"J'aime la programmation.\")"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "system_message = \"You are a helpful assistant who translates English to French.\"\n",
        "human_message = \"Translate this sentence from English to French. I love programming.\"\n",
        "\n",
        "messages = [SystemMessage(content=system_message), HumanMessage(content=human_message)]\n",
        "prompt = ChatPromptTemplate.from_messages(messages)\n",
        "\n",
        "chat = ChatVertexAI(\n",
        "    model_name=\"gemini-1.0-pro\",\n",
        "    convert_system_message_to_human=True,\n",
        "    safety_settings={\n",
        "        HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_LOW_AND_ABOVE\n",
        "    },\n",
        ")\n",
        "\n",
        "chain = prompt | chat\n",
        "chain.invoke({})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lB50i-JG9RQp"
      },
      "source": [
        "### Use a conversation chain\n",
        "\n",
        "You also can wrap up a chat in `ConversationChain`, which has built-in memory for remembering past user inputs and model outputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 1452,
          "status": "ok",
          "timestamp": 1709890734326,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -60
        },
        "id": "UFxQ6AN_5vDQ",
        "outputId": "b89a2962-b45b-472a-b0b1-65328e5fbb5f",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSystem: You are a helpful assistant who is good at language translation.\n",
            "Human: Translate this sentence from English to French. I love programming.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'input': 'Translate this sentence from English to French. I love programming.',\n",
              " 'history': [HumanMessage(content='Translate this sentence from English to French. I love programming.'),\n",
              "  AIMessage(content=\"J'adore la programmation.\")],\n",
              " 'response': \"J'adore la programmation.\"}"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = ChatVertexAI(\n",
        "    model_name=\"gemini-1.0-pro\",\n",
        "    convert_system_message_to_human=True,\n",
        "    safety_settings={\n",
        "        HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_LOW_AND_ABOVE\n",
        "    },\n",
        ")\n",
        "\n",
        "prompt = ChatPromptTemplate(\n",
        "    messages=[\n",
        "        SystemMessagePromptTemplate.from_template(\n",
        "            \"You are a helpful assistant who is good at language translation.\"\n",
        "        ),\n",
        "        MessagesPlaceholder(variable_name=\"history\"),\n",
        "        HumanMessagePromptTemplate.from_template(\"{input}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "memory = ConversationBufferMemory(memory_key=\"history\", return_messages=True)\n",
        "conversation = ConversationChain(llm=model, prompt=prompt, verbose=True, memory=memory)\n",
        "\n",
        "conversation.invoke(\n",
        "    input=\"Translate this sentence from English to French. I love programming.\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 2,
          "status": "ok",
          "timestamp": 1709890738554,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -60
        },
        "id": "AJMP2JrMDmS-",
        "outputId": "a1b80e08-4281-4a25-c7f8-0f90112931f8",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mSystem: You are a helpful assistant who is good at language translation.\n",
            "Human: Translate this sentence from English to French. I love programming.\n",
            "AI: J'adore la programmation.\n",
            "Human: Translate it to Spanish\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'input': 'Translate it to Spanish',\n",
              " 'history': [HumanMessage(content='Translate this sentence from English to French. I love programming.'),\n",
              "  AIMessage(content=\"J'adore la programmation.\"),\n",
              "  HumanMessage(content='Translate it to Spanish'),\n",
              "  AIMessage(content='Me encanta programar.')],\n",
              " 'response': 'Me encanta programar.'}"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conversation.invoke(\"Translate it to Spanish\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "intro_gemini_chat.ipynb",
      "provenance": []
    },
    "environment": {
      "kernel": "conda-root-py",
      "name": "workbench-notebooks.m115",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/workbench-notebooks:m115"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel) (Local)",
      "language": "python",
      "name": "conda-root-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
